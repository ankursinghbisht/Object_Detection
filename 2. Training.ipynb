{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638d4fe2",
   "metadata": {},
   "source": [
    "# Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34423e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the os module for operating system-related functionality\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model name for the project\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "\n",
    "# Pretrained model details\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# Script for generating TFRecord\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "\n",
    "# Label map file name\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing various paths used in the project\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing file paths\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc805af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories if they don't exist\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bfdb2",
   "metadata": {},
   "source": [
    "# Cloning Tensorflow Pretrained models ( TF Model Zoo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility module for downloading files from the internet.\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory containing TensorFlow object detection code does not exist\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    \n",
    "    # Clone the TensorFlow models repository from GitHub into the specified path\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcec34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for downloading the Protocol Buffers compiler zip file\n",
    "url = \"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "\n",
    "# Download the Protocol Buffers compiler zip file\n",
    "wget.download(url)\n",
    "\n",
    "# Move the downloaded file to the specified PROTOC_PATH\n",
    "!move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "\n",
    "# Navigate to the PROTOC_PATH and extract the contents of the zip file\n",
    "!cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "\n",
    "# Add the bin directory of the Protocol Buffers compiler to the PATH environment variable\n",
    "os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
    "\n",
    "# Navigate to the TensorFlow models research directory and compile Protocol Buffers proto files\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# Copy setup.py file from object_detection/packages/tf2 to the research directory\n",
    "# Build and install the object_detection package\n",
    "!cd Tensorflow/models/research && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "\n",
    "# Navigate to the slim directory and install the slim package\n",
    "!cd Tensorflow/models/research/slim && pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a173188",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing modules absent while verifing files ( missing modules are variable with each installation )\n",
    "\n",
    "!pip install tensorflow-gpu==2.10.0\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install pyyaml\n",
    "!pip install matplotlib\n",
    "!pip install protobuf==3.20.0\n",
    "!pip install pytz\n",
    "!pip install tzdata==2022.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pre-trained model from the specified URL\n",
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "\n",
    "# Move the downloaded tar.gz file to the PRETRAINED_MODEL_PATH\n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "\n",
    "# Navigate to the PRETRAINED_MODEL_PATH and extract the contents of the tar.gz file\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07dcc3",
   "metadata": {},
   "source": [
    "# Creating Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels, each with a name and an ID\n",
    "labels = [{'name':'Face', 'id':1},{'name':'ThumbsUp', 'id':2},{'name':'iLoveYou', 'id':3},\n",
    "          {'name':'Hello', 'id':4},{'name':'ThankYou', 'id':5}, {'name':'Yes', 'id':6},\n",
    "          {'name':'No', 'id':7},{'name':'Victory', 'id':8}]\n",
    "\n",
    "# Open the label map file for writing\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    # Iterate over each label and write the corresponding entries in the label map\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')               # Write the start of an item entry\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))  # Write the class name\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))          # Write the class ID\n",
    "        f.write('}\\n')                    # Write the end of the item entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93578137",
   "metadata": {},
   "source": [
    "# Creating Tensorflow records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file generate_tfrecord.py does not exist\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    \n",
    "    # Clone the specified GitHub repository into the SCRIPTS_PATH\n",
    "    !git clone https://github.com/ankursinghbisht/GenerateTFRecord {paths['SCRIPTS_PATH']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5962b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the generate_tfrecord.py script for training data\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
    "# Run the generate_tfrecord.py script for testing data\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7109e334",
   "metadata": {},
   "source": [
    "# Copying Model Config to Training Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a228eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the 'pipeline.config' file from the pretrained model directory to the checkpoint directory\n",
    "!copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57d646",
   "metadata": {},
   "source": [
    "# 5. Updating Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing pipeline configuration from the file\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1697016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the pipeline configuration file and merge it with the protobuf message\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify specific parameters in the pipeline configuration for transfer learning\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56817134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the modified pipeline configuration back to a text format\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "\n",
    "# Write the updated configuration back to the pipeline configuration file\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c26b100",
   "metadata": {},
   "source": [
    "# 6. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083630a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the training script in the TensorFlow object detection API\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the command for training the model\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84952bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructed command for training the object detection model\n",
    "print(command)\n",
    "\n",
    "# Explanation:\n",
    "# python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py\n",
    "# This is the Python interpreter and the path to the training script (model_main_tf2.py).\n",
    "\n",
    "# --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet\n",
    "# This flag specifies the directory where the trained model checkpoints and event logs will be saved.\n",
    "# The model directory is set to Tensorflow\\workspace\\models\\my_ssd_mobnet.\n",
    "\n",
    "# --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config\n",
    "# This flag specifies the path to the pipeline configuration file.\n",
    "# The pipeline configuration file contains settings for the model architecture, training parameters, and input data configuration.\n",
    "# The path is set to Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config.\n",
    "\n",
    "# --num_train_steps=X\n",
    "# This flag specifies the number of training steps.\n",
    "# In this case, it is set to X, meaning the model will be trained for X steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the training command\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a43c3",
   "metadata": {},
   "source": [
    "# Evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd15070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the evaluation script\n",
    "EVALUATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for evaluation\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(\n",
    "    EVALUATION_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c836392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ObjectDetection",
   "language": "python",
   "name": "objectdetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
