{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f941843",
   "metadata": {},
   "source": [
    "# Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfedaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the os module for operating system-related functionality\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model name for the project\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "\n",
    "# Pretrained model details\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# Script for generating TFRecord\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "\n",
    "# Label map file name\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521af6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing various paths used in the project\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082720b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing file paths\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories if they don't exist\n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11017e1",
   "metadata": {},
   "source": [
    "# Cloning Tensorflow Pretrained models ( TF Model Zoo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90611150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility module for downloading files from the internet.\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a83309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory containing TensorFlow object detection code does not exist\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    \n",
    "    # Clone the TensorFlow models repository from GitHub into the specified path\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396700e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for downloading the Protocol Buffers compiler zip file\n",
    "url = \"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "\n",
    "# Download the Protocol Buffers compiler zip file\n",
    "wget.download(url)\n",
    "\n",
    "# Move the downloaded file to the specified PROTOC_PATH\n",
    "!move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "\n",
    "# Navigate to the PROTOC_PATH and extract the contents of the zip file\n",
    "!cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "\n",
    "# Add the bin directory of the Protocol Buffers compiler to the PATH environment variable\n",
    "os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
    "\n",
    "# Navigate to the TensorFlow models research directory and compile Protocol Buffers proto files\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# Copy setup.py file from object_detection/packages/tf2 to the research directory\n",
    "# Build and install the object_detection package\n",
    "!cd Tensorflow/models/research && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "\n",
    "# Navigate to the slim directory and install the slim package\n",
    "!cd Tensorflow/models/research/slim && pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974fe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67245208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing modules absent while verifing files ( missing modules are variable with each installation )\n",
    "\n",
    "!pip install tensorflow-gpu==2.10.0\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install pyyaml\n",
    "!pip install matplotlib\n",
    "!pip install protobuf==3.20.0\n",
    "!pip install pytz\n",
    "!pip install tzdata==2022.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b48d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pre-trained model from the specified URL\n",
    "wget.download(PRETRAINED_MODEL_URL)\n",
    "\n",
    "# Move the downloaded tar.gz file to the PRETRAINED_MODEL_PATH\n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "\n",
    "# Navigate to the PRETRAINED_MODEL_PATH and extract the contents of the tar.gz file\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7998e",
   "metadata": {},
   "source": [
    "# Creating Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels, each with a name and an ID\n",
    "labels = [{'name':'Face', 'id':1},{'name':'ThumbsUp', 'id':2},{'name':'ThumbsDown', 'id':3},\n",
    "          {'name':'Hello', 'id':4},{'name':'ThankYou', 'id':5}, {'name':'Yes', 'id':6},\n",
    "          {'name':'No', 'id':7}, {'name':'LiveLong', 'id':8}]\n",
    "\n",
    "# Open the label map file for writing\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    # Iterate over each label and write the corresponding entries in the label map\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')               # Write the start of an item entry\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))  # Write the class name\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))          # Write the class ID\n",
    "        f.write('}\\n')                    # Write the end of the item entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c39fb",
   "metadata": {},
   "source": [
    "# Creating Tensorflow records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file generate_tfrecord.py does not exist\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    \n",
    "    # Clone the specified GitHub repository into the SCRIPTS_PATH\n",
    "    !git clone https://github.com/ankursinghbisht/GenerateTFRecord {paths['SCRIPTS_PATH']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8626c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the generate_tfrecord.py script for training data\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
    "# Run the generate_tfrecord.py script for testing data\n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ObjectDetection",
   "language": "python",
   "name": "objectdetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
